{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import transformers\n",
    "\n",
    "# ######################## PART 1: PROVIDED CODE ########################\n",
    "\n",
    "def load_datasets(data_directory: str) -> Union[dict, dict]:\n",
    "    \"\"\"\n",
    "    Reads the training and validation splits from disk and load\n",
    "    them into memory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_directory: str\n",
    "        The directory where the data is stored.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    train: dict\n",
    "        The train dictionary with keys 'premise', 'hypothesis', 'label'.\n",
    "    validation: dict\n",
    "        The validation dictionary with keys 'premise', 'hypothesis', 'label'.\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import os\n",
    "\n",
    "    with open(os.path.join(data_directory, \"train.json\"), \"r\") as f:\n",
    "        train = json.load(f)\n",
    "\n",
    "    with open(os.path.join(data_directory, \"validation.json\"), \"r\") as f:\n",
    "        valid = json.load(f)\n",
    "\n",
    "    return train, valid\n",
    "\n",
    "\n",
    "class NLIDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dict: dict):\n",
    "        self.data_dict = data_dict\n",
    "        dd = data_dict\n",
    "\n",
    "        if len(dd[\"premise\"]) != len(dd[\"hypothesis\"]) or len(dd[\"premise\"]) != len(\n",
    "            dd[\"label\"]\n",
    "        ):\n",
    "            raise AttributeError(\"Incorrect length in data_dict\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_dict[\"premise\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dd = self.data_dict\n",
    "        return dd[\"premise\"][idx], dd[\"hypothesis\"][idx], dd[\"label\"][idx]\n",
    "\n",
    "\n",
    "def train_distilbert(model, loader, device):\n",
    "    model.train()\n",
    "    criterion = model.get_criterion()\n",
    "    total_loss = 0.0\n",
    "    train_accuracy = []\n",
    "    for premise, hypothesis, target in tqdm(loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = model.tokenize(premise, hypothesis).to(device)\n",
    "        target = target.to(device, dtype=torch.float32)\n",
    "        #print(inputs)\n",
    "        pred = model(inputs)\n",
    "        #print(pred)\n",
    "        #print(target)\n",
    "        loss = criterion(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(\"training accuracy is \")\n",
    "    accuracy = torch.eq(target, pred.round())\n",
    "    true_count = 0\n",
    "    all_count = 0\n",
    "    # Loop through each element\n",
    "    for element in accuracy:\n",
    "        all_count += 1\n",
    "        if element:  # Check if element is True\n",
    "             true_count += 1\n",
    "    print(true_count/all_count)\n",
    "    return total_loss / len(loader), true_count/all_count\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_distilbert(model, loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    targets = []\n",
    "    preds = []\n",
    "\n",
    "    for premise, hypothesis, target in loader:\n",
    "        preds.append(model(model.tokenize(premise, hypothesis).to(device)))\n",
    "\n",
    "        targets.append(target)\n",
    "\n",
    "    return torch.cat(preds), torch.cat(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A4 START HERE\n",
    "class CustomDistilBert(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.distilbert = transformers.DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.tokenizer = transformers.DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.pred_layer = nn.Linear(self.distilbert.config.hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "    # vvvvv DO NOT CHANGE BELOW THIS LINE vvvvv\n",
    "    def get_distilbert(self):\n",
    "        return self.distilbert\n",
    "\n",
    "    def get_tokenizer(self):\n",
    "        return self.tokenizer\n",
    "\n",
    "    def get_pred_layer(self):\n",
    "        return self.pred_layer\n",
    "\n",
    "    def get_sigmoid(self):\n",
    "        return self.sigmoid\n",
    "    \n",
    "    def get_criterion(self):\n",
    "        return self.criterion\n",
    "    # ^^^^^ DO NOT CHANGE ABOVE THIS LINE ^^^^^\n",
    "\n",
    "    def assign_optimizer(self, **kwargs):\n",
    "        model_params = self.parameters()\n",
    "        optimizer = torch.optim.Adam(model_params, **kwargs)  \n",
    "        return optimizer\n",
    "\n",
    "    def slice_cls_hidden_state(\n",
    "        self, x: transformers.modeling_outputs.BaseModelOutput\n",
    "    ) -> torch.Tensor:\n",
    "        last_states = x.last_hidden_state\n",
    "        result =last_states[:, 0, :]\n",
    "        return result\n",
    "\n",
    "    def tokenize(\n",
    "        self,\n",
    "        premise: \"list[str]\",\n",
    "        hypothesis: \"list[str]\",\n",
    "        max_length: int = 128,\n",
    "        truncation: bool = True,\n",
    "        padding: bool = True,\n",
    "    ):\n",
    "        tokenizer = self.get_tokenizer()\n",
    "        encoded_inputs = tokenizer(premise, hypothesis,\n",
    "                              max_length=max_length,\n",
    "                              truncation=truncation,\n",
    "                              padding=padding,\n",
    "                              return_tensors=\"pt\")\n",
    "        return encoded_inputs\n",
    "\n",
    "    def forward(self, inputs: transformers.BatchEncoding):\n",
    "        #print(inputs)\n",
    "        outputs = self.distilbert(**inputs)\n",
    "        cls_token_hidden_state = self.slice_cls_hidden_state(outputs)\n",
    "        zero_one = self.pred_layer(cls_token_hidden_state)\n",
    "        #print(zero_one)\n",
    "        predictions = self.sigmoid(zero_one)\n",
    "        return predictions[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Running test code for part 1\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [05:21<00:00,  8.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy is \n",
      "0.75\n",
      "validation accuracy is \n",
      "0.848\n",
      "Epoch: 0\n",
      "Training loss: 0.5917958706617356\n",
      "Validation F1 score: 0.8364888123924269\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [05:53<00:00,  8.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy is \n",
      "0.5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[103], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m loss, train_acc \u001b[38;5;241m=\u001b[39m train_distilbert(model, train_loader, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     44\u001b[0m training_accuracy\u001b[38;5;241m.\u001b[39mappend(train_acc)\n\u001b[1;32m---> 45\u001b[0m preds, targets \u001b[38;5;241m=\u001b[39m \u001b[43meval_distilbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m#print(\"validation accuracy is \")\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m#accuracy = torch.mean(torch.eq(target, pred.round())).item()\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m#print(accuracy)\u001b[39;00m\n\u001b[0;32m     49\u001b[0m preds \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mround()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[101], line 102\u001b[0m, in \u001b[0;36meval_distilbert\u001b[1;34m(model, loader, device)\u001b[0m\n\u001b[0;32m     99\u001b[0m preds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m premise, hypothesis, target \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m--> 102\u001b[0m     preds\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpremise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypothesis\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    104\u001b[0m     targets\u001b[38;5;241m.\u001b[39mappend(target)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(preds), torch\u001b[38;5;241m.\u001b[39mcat(targets)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[87], line 58\u001b[0m, in \u001b[0;36mCustomDistilBert.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: transformers\u001b[38;5;241m.\u001b[39mBatchEncoding):\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;66;03m#print(inputs)\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistilbert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m     cls_token_hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice_cls_hidden_state(outputs)\n\u001b[0;32m     60\u001b[0m     zero_one \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_layer(cls_token_hidden_state)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:820\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    818\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(input_shape, device\u001b[38;5;241m=\u001b[39mdevice)  \u001b[38;5;66;03m# (bs, seq_length)\u001b[39;00m\n\u001b[1;32m--> 820\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:585\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    577\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    578\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    579\u001b[0m         hidden_state,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    582\u001b[0m         output_attentions,\n\u001b[0;32m    583\u001b[0m     )\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 585\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    592\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:530\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;66;03m# Feed Forward Network\u001b[39;00m\n\u001b[0;32m    529\u001b[0m ffn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn(sa_output)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m--> 530\u001b[0m ffn_output: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_layer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mffn_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msa_output\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    532\u001b[0m output \u001b[38;5;241m=\u001b[39m (ffn_output,)\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1514\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1511\u001b[0m             tracing_state\u001b[38;5;241m.\u001b[39mpop_scope()\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1516\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score  # Make sure sklearn is installed\n",
    "import random\n",
    "random.seed(2022)\n",
    "torch.manual_seed(2022)\n",
    "\n",
    "# Parameters (you can change them)\n",
    "sample_size = 2500  # Change this if you want to take a subset of data for testing\n",
    "batch_size = 64\n",
    "n_epochs = 10\n",
    "num_words = 50000\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_raw, valid_raw = load_datasets(\"./data/nli\")\n",
    "if sample_size is not None:\n",
    "        for key in [\"premise\", \"hypothesis\", \"label\"]:\n",
    "            train_raw[key] = train_raw[key][:sample_size]\n",
    "            valid_raw[key] = valid_raw[key][:sample_size]\n",
    "            \n",
    "full_text = (\n",
    "        train_raw[\"premise\"]\n",
    "        + train_raw[\"hypothesis\"]\n",
    "        + valid_raw[\"premise\"]\n",
    "        + valid_raw[\"hypothesis\"]\n",
    "    )\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Running test code for part 1\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        NLIDataset(train_raw), batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "        NLIDataset(valid_raw), batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "model = CustomDistilBert().to(device)\n",
    "#optimizer = model.assign_optimizer(lr=1e-4)\n",
    "optimizer = model.assign_optimizer(lr=1e-4)\n",
    "validation_accuracy = []\n",
    "training_accuracy = []\n",
    "for epoch in range(n_epochs):\n",
    "        loss, train_acc = train_distilbert(model, train_loader, device=device)\n",
    "        training_accuracy.append(train_acc)\n",
    "        preds, targets = eval_distilbert(model, valid_loader, device=device)\n",
    "        #print(\"validation accuracy is \")\n",
    "        #accuracy = torch.mean(torch.eq(target, pred.round())).item()\n",
    "        #print(accuracy)\n",
    "        preds = preds.round()\n",
    "        print(\"validation accuracy is \")\n",
    "        accuracy = torch.eq(targets, preds.round())\n",
    "        true_count = 0\n",
    "        all_count = 0\n",
    "        # Loop through each element\n",
    "        for element in accuracy:\n",
    "            all_count += 1\n",
    "            if element:  # Check if element is True\n",
    "                true_count += 1\n",
    "        print(true_count/all_count)\n",
    "        validation_accuracy.append(true_count/all_count)\n",
    "        score = f1_score(targets.cpu(), preds.cpu())\n",
    "        print(\"Epoch:\", epoch)\n",
    "        print(\"Training loss:\", loss)\n",
    "        print(\"Validation F1 score:\", score)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A woman wearing a bike helmet and a warm-up suit is sitting in the park meditating.\n",
      "A woman is sitting.\n",
      "0\n",
      "A child in a tie dye shirt and one in a white shirt are on a climbing wall.\n",
      "Two children climb a wall.\n",
      "0\n",
      "Two brown dogs barking at each other.\n",
      "The animals are making noise.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_raw['premise'][0])\n",
    "print(train_raw['hypothesis'][0])\n",
    "print(train_raw['label'][0])\n",
    "print(train_raw['premise'][1])\n",
    "print(train_raw['hypothesis'][1])\n",
    "print(train_raw['label'][1])\n",
    "print(train_raw['premise'][2])\n",
    "print(train_raw['hypothesis'][2])\n",
    "print(train_raw['label'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Man with dreadlocks twirling batons near boats.\n",
      "The man is sewing a boat sail.\n",
      "1\n",
      "A worker with face protection is using a machine.\n",
      "a worker is working\n",
      "0\n",
      "four friends cheerfully jumping off the flight stairs.\n",
      "Four people jumping off stairs.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_raw['premise'][8])\n",
    "print(train_raw['hypothesis'][8])\n",
    "print(train_raw['label'][8])\n",
    "print(train_raw['premise'][7])\n",
    "print(train_raw['hypothesis'][7])\n",
    "print(train_raw['label'][7])\n",
    "print(train_raw['premise'][6])\n",
    "print(train_raw['hypothesis'][6])\n",
    "print(train_raw['label'][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_params(model):\n",
    "    # TODO: your work below\n",
    "    for param in model.parameters(recurse=True):\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "def pad_attention_mask(mask, p):\n",
    "    print(mask)\n",
    "    print(p)\n",
    "    padded_mask = torch.nn.functional.pad(mask, (p, 0), value=1) \n",
    "    print(padded_mask)\n",
    "    return padded_mask\n",
    "\n",
    "\n",
    "class SoftPrompting(nn.Module):\n",
    "    def __init__(self, p: int, e: int):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.e = e\n",
    "        \n",
    "        self.prompts = torch.randn((p, e), requires_grad=True)\n",
    "        \n",
    "    def forward(self, embedded):\n",
    "        batch_prompts = self.prompts.unsqueeze(0).expand(embedded.size(0), -1, -1)\n",
    "        prompted_embeddings = torch.cat([batch_prompts, embedded], dim=1)\n",
    "        return prompted_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,   101,  2054,  2828,  1997,  5404,  2003,  2190,  2005,  5404,\n",
      "         17548,  3869,  1029,   102,  1045,  2001,  2559,  2005,  1037,  5404,\n",
      "         17548,  3869, 17974,  1996,  2060,  2154,  2043,  1045,  4384,  2087,\n",
      "          1997,  1996, 19328,  2123,  1005,  1056,  2110,  1037,  2806,  1997,\n",
      "          5404,  2000,  2224,  1012,  2070,  1997,  1996, 19328,  2224,  1037,\n",
      "          3278,  3815,  1997,  5404,  2061,  1045,  7868,  2008,  2070,  1997,\n",
      "          1996, 14894,  6337,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "{'input_ids': tensor([[  101,   101,  2043,  7842, 10421,  2075,  2323,  1045,  2404, 20949,\n",
      "          2030, 20548,  2034,  1029,   102,  2087,  1997,  1996, 10447,  2182,\n",
      "          1999,  1996,  5137,  2920,  7842, 10421,  2075,  1012,  2021,  1045,\n",
      "          2572,  1037,  2210,  2978,  5457,  2006,  2054,  2323,  1045,  2404,\n",
      "          2034,  1010,  2024,  2045,  2151, 12637,  2006,  2009,  1029,  1008,\n",
      "          1008,  3980,  1024,  1008,  1008,  1015,  1012,  2323,  1045,  2404,\n",
      "         20949,  2030, 20548,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "{'input_ids': tensor([[  101,   101,  2129,  2146,  2079,  4895,  2890, 19699, 17071,  4383,\n",
      "          2441, 27141, 23582,  2197,  1029,   102,  1045,  2363,  1037,  3232,\n",
      "         25628, 18484,  1997, 15212, 23582,  2008,  2020, 27141,  2007,  1037,\n",
      "         14855,  2721, 11837,  2080,  1999,  2169,  2005,  2070,  4469,  3684,\n",
      "          1012,  1045,  7078,  2293,  1996,  5510,  1997,  2068,  1010,  2021,\n",
      "          1045,  2572,  8025,  2129,  2146,  2027,  2064,  2197,  2320,  2441,\n",
      "          2043,  2045,  3475,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "{'input_ids': tensor([[  101,   101,  9166, 15653, 11227,  1006,  1047, 10606, 28613,  1007,\n",
      "         13423,  2000,  1996,  3953,  1997,  1996,  8962,   102,  1047, 10606,\n",
      "         28613,  2024, 17020,  6240, 15653, 11227,  2013,  1996,  9166, 12846,\n",
      "          1012,  2027,  1005,  2128,  2719,  5128,  2055,  1037, 15642,  3993,\n",
      "          1997,  2598, 15960,  1009, 12486,  6240,  2007,  2300,  1998, 21729,\n",
      "          1999,  1996,  2415,  1997,  1037,  2261,  4971, 28136,  4317, 23126,\n",
      "          9785,  2029,  2003,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "{'input_ids': tensor([[  101,   101,  2887,  2744,  2005,  2043,  1996, 10514,  6182, 10026,\n",
      "         20776,  7954,  2005,  2017,   102,  2054,  2003,  1996,  2887,  2744,\n",
      "          2005,  2043,  1996, 10514,  6182, 10026, 20776,  1037, 10514,  6182,\n",
      "          7954,  2005,  2017,  2241,  2006,  2054,  1996, 10514,  6182, 10026,\n",
      "          9266,  5244,  2000,  2022,  4840,  1998,  2204,  1010,  2004,  2092,\n",
      "          2004,  2054,  2017,  2052,  2022,  4699,  1999,  5983,  1029,  1045,\n",
      "          2903,  2023,  2003,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "{'input_ids': tensor([[  101,   101,  2003, 11840,  8411,  2013,  6763,  1037,  2149,  1011,\n",
      "          2069,  3291,  1029,   102,  1037,  1031,  8224,  2005,  1000,  2885,\n",
      "          8288,  9378,  1000,  1033,  1006, 16770,  1024,  1013,  1013,  7479,\n",
      "          1012,  8224,  1012,  4012,  1012,  8740,  1013,  3945,  1029,  1053,\n",
      "          1027,  2885,  1003,  2322, 13910,  2290,  1003,  2322, 28556,  1007,\n",
      "          2097,  2265,  2039,  1037,  2843,  1997,  5875,  3463,  2055,  5966,\n",
      "          1999,  8288,  6364,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "{'input_ids': tensor([[  101,   101,  2003,  2009,  3647,  2000, 26077, 14380,  2300,  1029,\n",
      "           102,  2003,  2009,  3100,  2005,  2033,  2000,  4666, 14380, 10869,\n",
      "          1998,  2300,  1010,  2084,  3288,  2000,  1037, 26077,  2006,  1996,\n",
      "         16247, 14399,  1029,  1045,  2215,  2000,  2191,  1996,  2160,  5437,\n",
      "          2066, 14380,  2015,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "{'input_ids': tensor([[  101,   101,  2076, 13109,  3286,  4783,  1010,  2054,  2003,  1996,\n",
      "          9898,  2008,  2003, 16697,  2046,  1996,  2543,  2000,  3443, 12300,\n",
      "          1029,   102,  2026, 25380,  2005,  1037,  3768,  1997,  4957,  1010,\n",
      "          2348, 11504,  2026,  6412,  2097, 10514, 26989,  3401,  1012,  1045,\n",
      "          2387,  2070, 25354,  2678,  1997, 27828,  2437,  1031, 26191,  6469,\n",
      "          1033,  1006,  8299,  1024,  1013,  1013,  4372,  1012, 16948,  1012,\n",
      "          8917,  1013, 15536,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "def load_models_and_tokenizer(q_name, a_name, t_name, device='cpu'):\n",
    "    # TODO: your work below\n",
    "    q_enc = transformers.AutoModel.from_pretrained(q_name).to(device)\n",
    "    a_enc =  transformers.AutoModel.from_pretrained(a_name).to(device)\n",
    "    tokenizer =  transformers.AutoTokenizer.from_pretrained(t_name)\n",
    "    return q_enc, a_enc, tokenizer\n",
    "    \n",
    "\n",
    "def tokenize_qa_batch(tokenizer, q_titles, q_bodies, answers, max_length=64) -> transformers.BatchEncoding:\n",
    "    q_text = [\"[CLS] \" +title+ \" [SEP] \" + body for title, body in zip(q_titles, q_bodies)]\n",
    "    for text in q_text:\n",
    "        q = tokenizer(text, padding=True, return_token_type_ids= True, return_attention_mask=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "        print(q)\n",
    "    a_batch= tokenizer(answers, padding=True, return_token_type_ids= True, return_attention_mask=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    return [], a_batch\n",
    "    \n",
    "    # return q_batch, a_batch\n",
    "\n",
    "def get_class_output(model, batch):\n",
    "    # Since this is similar to a previous question, it is left ungraded\n",
    "    # TODO: your work below.\n",
    "    print(q_)\n",
    "    pass\n",
    "\n",
    "def inbatch_negative_sampling(Q: Tensor, P: Tensor, device: str = 'cpu') -> Tensor:\n",
    "    # TODO: your work below\n",
    "    # Calculate dot product similarity between questions and all passages in the batch\n",
    "    S = torch.einsum('ne,me->nm', Q, P) \n",
    "    mean_negatives = torch.mean(S, dim=1, keepdim=True)  \n",
    "    S = S - mean_negatives\n",
    "    return S.to(device) \n",
    "    \n",
    "    # return S\n",
    "\n",
    "def contrastive_loss_criterion(S: Tensor, labels: Tensor = None, device: str = 'cpu'):\n",
    "    # TODO: your work below\n",
    "    pass\n",
    "    \n",
    "    # return loss\n",
    "\n",
    "def get_topk_indices(Q, P, k: int = None):\n",
    "    # TODO: your work below\n",
    "    pass\n",
    "\n",
    "    # return indices, scores\n",
    "\n",
    "def select_by_indices(indices: Tensor, passages: 'list[str]') -> 'list[str]':\n",
    "    # TODO: your work below\n",
    "    pass\n",
    "\n",
    "\n",
    "def embed_passages(passages: 'list[str]', model, tokenizer, device='cpu', max_length=512):\n",
    "    # TODO: your work below\n",
    "    pass\n",
    "\n",
    "\n",
    "def embed_questions(titles, bodies, model, tokenizer, device='cpu', max_length=512):\n",
    "    # TODO: your work below\n",
    "    pass\n",
    "\n",
    "\n",
    "def recall_at_k(retrieved_indices: 'list[list[int]]', true_indices: 'list[int]', k: int):\n",
    "    # TODO: your work below\n",
    "    pass\n",
    "\n",
    "\n",
    "def mean_reciprocal_rank(retrieved_indices: 'list[list[int]]', true_indices: 'list[int]'):\n",
    "    # TODO: your work below\n",
    "    pass\n",
    "\n",
    "\n",
    "bsize = 8\n",
    "qa_data = dict(\n",
    "        train = pd.read_csv('data/qa/train.csv'),\n",
    "        valid = pd.read_csv('data/qa/validation.csv'),\n",
    "        answers = pd.read_csv('data/qa/answers.csv'),\n",
    "    )\n",
    "\n",
    "q_titles = qa_data['train'].loc[:bsize-1, 'QuestionTitle'].tolist()\n",
    "q_bodies = qa_data['train'].loc[:bsize-1, 'QuestionBody'].tolist()\n",
    "answers = qa_data['train'].loc[:bsize-1, 'Answer'].tolist()\n",
    "\n",
    "    # Loading huggingface models and tokenizers    \n",
    "name = 'google/electra-small-discriminator'\n",
    "q_enc, a_enc, tokenizer = load_models_and_tokenizer(q_name=name, a_name=name, t_name=name)\n",
    "q_batch, a_batch = tokenize_qa_batch(tokenizer, q_titles, q_bodies, answers)\n",
    "#q_out = get_class_output(q_enc, q_batch)\n",
    "#a_out = get_class_output(a_enc, a_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_batch['input_ids'].size()\n",
    "print(q_batch['token_type_ids'].size())\n",
    "q_batch['attention_mask'].size()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
